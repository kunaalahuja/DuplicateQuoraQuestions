{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Quora.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ta0LuveeaRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "beeae277-5550-4f2c-bbb3-fc058f4e6a00"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import pprint\n",
        "%tensorflow_version 1.15\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBc8vZlQQwFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "10c4aec1-7810-482f-b5b0-3eb09f3d4ca8"
      },
      "source": [
        "# Authenticate, so we can access storage bucket and TPU\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "USE_TPU = True\n",
        "\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "# Bucket for saving checkpoints and outputs\n",
        "BUCKET = 'nlp_bert_quora' \n",
        "if BUCKET!=\"\":\n",
        "  OUTPUT_DIR = 'gs://{}/outputs'.format(BUCKET)\n",
        "  tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "elif USE_TPU:\n",
        "  raise ValueError('Must specify an existing GCS bucket name for running on TPU')\n",
        "else:\n",
        "  OUTPUT_DIR = 'out_dir'\n",
        "  os.mkdir(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "if USE_TPU:\n",
        "  # getting info on TPU runtime\n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; Change notebook runtype to TPU'\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print('TPU address is', TPU_ADDRESS)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n",
            "***** Model output directory: gs://nlp_bert_quora/outputs *****\n",
            "TPU address is grpc://10.92.11.106:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS20QCJ5Ci9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "# BERT_PRETRAINED_DIR = BERT_MODEL\n",
        "# OUTPUT_DIR = 'out_dir'\n",
        "# try: \n",
        "#   os.mkdir(OUTPUT_DIR)\n",
        "# except:\n",
        "#   print(\"already exists\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtxc__HMeZEk",
        "colab_type": "code",
        "outputId": "672b3888-5478-4e14-a2c9-63219c0eba61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import run_classifier\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 2.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 200 \n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xdjfo96v4by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Authenticate, so we can access storage bucket and TPU\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# USE_TPU = True #@param{type:\"boolean\"}\n",
        "# BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "\n",
        "# BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "# print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "# !gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "\n",
        "# BUCKET = 'nlp_bert_quora' #@param {type:\"string\"}\n",
        "# if BUCKET!=\"\":\n",
        "#   OUTPUT_DIR = 'gs://{}/outputs'.format(BUCKET)\n",
        "#   tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "# elif USE_TPU:\n",
        "#   raise ValueError('Must specify an existing GCS bucket name for running on TPU')\n",
        "# else:\n",
        "#   OUTPUT_DIR = 'out_dir'\n",
        "#   os.mkdir(OUTPUT_DIR)\n",
        "# print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# if USE_TPU:\n",
        "#   # getting info on TPU runtime\n",
        "#   assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; Change notebook runtype to TPU'\n",
        "#   TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "#   print('TPU address is', TPU_ADDRESS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AdK2F6pmm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "19256b84-22b8-448f-8887-cf176e8e565e"
      },
      "source": [
        "!test -d bert || git clone -q https://github.com/google-research/bert.git\n",
        "if not 'bert' in sys.path:\n",
        "  sys.path += ['bert']\n",
        "TASK_DATA_DIR = 'glue_data/QQP'\n",
        "!test -d glue_data || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git glue_data\n",
        "!test -d $TASK_DATA_DIR || python glue_data/download_glue_data.py --data_dir glue_data --tasks=QQP\n",
        "!ls -als $TASK_DATA_DIR"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 106400\n",
            "    4 drwxr-xr-x 3 root root     4096 Mar 28 03:54 .\n",
            "    4 drwxr-xr-x 4 root root     4096 Mar 28 03:54 ..\n",
            " 5680 -rw-r--r-- 1 root root  5815716 Mar 28 03:54 dev.tsv\n",
            "    4 drwxr-xr-x 2 root root     4096 Mar 28 03:54 original\n",
            "49572 -rw-r--r-- 1 root root 50759408 Mar 28 03:54 test.tsv\n",
            "51136 -rw-r--r-- 1 root root 52360463 Mar 28 03:54 train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq-E4VsXgc8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QQPProcessor(run_classifier.DataProcessor):\n",
        "  \"\"\"Processor for the Quora Question pair data set.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"train.tsv\")), 'train')\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"Reading dev.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"dev.tsv\")), 'dev')\n",
        "  \n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"test.tsv\")), 'test')\n",
        "  \n",
        "  def get_predict_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=0))\n",
        "    return examples\n",
        "  \n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      guid = \"%s-%d\" % (set_type, i)\n",
        "      if set_type=='test':\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=3:\n",
        "          print(guid, line)\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[1])\n",
        "        text_b = tokenization.convert_to_unicode(line[2])\n",
        "        label = 0 # We will use zero for test as convert_example_to_features doesn't support None\n",
        "      else:\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=6:\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[3])\n",
        "        text_b = tokenization.convert_to_unicode(line[4])\n",
        "        label = int(line[5])\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"return class labels\"\n",
        "    return [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX87u-G95MmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4cb8ed48-32d5-475d-9460-8f749c94d9f3"
      },
      "source": [
        "# Instantiate an instance of QQPProcessor and tokenizer\n",
        "processor = QQPProcessor()\n",
        "label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnu5EeIT5Vow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e21ae74a-308e-4411-851c-837d690fb7ed"
      },
      "source": [
        "print(\"################  Processing Training Data #####################\")\n",
        "# TASK_DATA_DIR = \"glue_data\"\n",
        "TRAIN_TF_RECORD = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_examples = len(train_examples)\n",
        "num_train_steps = int( num_train_examples / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "run_classifier.file_based_convert_examples_to_features(train_examples, label_list, MAX_SEQ_LENGTH, tokenizer, TRAIN_TF_RECORD)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################  Processing Training Data #####################\n",
            "WARNING:tensorflow:From /content/run_classifier.py:199: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/run_classifier.py:483: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/run_classifier.py:487: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing example 0 of 363849\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1\n",
            "INFO:tensorflow:tokens: [CLS] how is the life of a math student ? could you describe your own experiences ? [SEP] which level of prep ##ration is enough for the exam j ##lp ##t ##5 ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2129 2003 1996 2166 1997 1037 8785 3076 1029 2071 2017 6235 2115 2219 6322 1029 102 2029 2504 1997 17463 8156 2003 2438 2005 1996 11360 1046 14277 2102 2629 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2\n",
            "INFO:tensorflow:tokens: [CLS] how do i control my horn ##y emotions ? [SEP] how do you control your horn ##iness ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2129 2079 1045 2491 2026 7109 2100 6699 1029 102 2129 2079 2017 2491 2115 7109 9961 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-3\n",
            "INFO:tensorflow:tokens: [CLS] what causes stool color to change to yellow ? [SEP] what can cause stool to come out as little balls ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 5320 14708 3609 2000 2689 2000 3756 1029 102 2054 2064 3426 14708 2000 2272 2041 2004 2210 7395 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-4\n",
            "INFO:tensorflow:tokens: [CLS] what can one do after mb ##bs ? [SEP] what do i do after my mb ##bs ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 2064 2028 2079 2044 16914 5910 1029 102 2054 2079 1045 2079 2044 2026 16914 5910 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-5\n",
            "INFO:tensorflow:tokens: [CLS] where can i find a power outlet for my laptop at melbourne airport ? [SEP] would a second airport in sydney , australia be needed if a high - speed rail link was created between melbourne and sydney ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2073 2064 1045 2424 1037 2373 13307 2005 2026 12191 2012 4940 3199 1029 102 2052 1037 2117 3199 1999 3994 1010 2660 2022 2734 2065 1037 2152 1011 3177 4334 4957 2001 2580 2090 4940 1998 3994 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 363849\n",
            "INFO:tensorflow:Writing example 20000 of 363849\n",
            "INFO:tensorflow:Writing example 30000 of 363849\n",
            "INFO:tensorflow:Writing example 40000 of 363849\n",
            "INFO:tensorflow:Writing example 50000 of 363849\n",
            "INFO:tensorflow:Writing example 60000 of 363849\n",
            "INFO:tensorflow:Writing example 70000 of 363849\n",
            "INFO:tensorflow:Writing example 80000 of 363849\n",
            "INFO:tensorflow:Writing example 90000 of 363849\n",
            "INFO:tensorflow:Writing example 100000 of 363849\n",
            "INFO:tensorflow:Writing example 110000 of 363849\n",
            "INFO:tensorflow:Writing example 120000 of 363849\n",
            "INFO:tensorflow:Writing example 130000 of 363849\n",
            "INFO:tensorflow:Writing example 140000 of 363849\n",
            "INFO:tensorflow:Writing example 150000 of 363849\n",
            "INFO:tensorflow:Writing example 160000 of 363849\n",
            "INFO:tensorflow:Writing example 170000 of 363849\n",
            "INFO:tensorflow:Writing example 180000 of 363849\n",
            "INFO:tensorflow:Writing example 190000 of 363849\n",
            "INFO:tensorflow:Writing example 200000 of 363849\n",
            "INFO:tensorflow:Writing example 210000 of 363849\n",
            "INFO:tensorflow:Writing example 220000 of 363849\n",
            "INFO:tensorflow:Writing example 230000 of 363849\n",
            "INFO:tensorflow:Writing example 240000 of 363849\n",
            "INFO:tensorflow:Writing example 250000 of 363849\n",
            "INFO:tensorflow:Writing example 260000 of 363849\n",
            "INFO:tensorflow:Writing example 270000 of 363849\n",
            "INFO:tensorflow:Writing example 280000 of 363849\n",
            "INFO:tensorflow:Writing example 290000 of 363849\n",
            "INFO:tensorflow:Writing example 300000 of 363849\n",
            "INFO:tensorflow:Writing example 310000 of 363849\n",
            "INFO:tensorflow:Writing example 320000 of 363849\n",
            "INFO:tensorflow:Writing example 330000 of 363849\n",
            "INFO:tensorflow:Writing example 340000 of 363849\n",
            "INFO:tensorflow:Writing example 350000 of 363849\n",
            "INFO:tensorflow:Writing example 360000 of 363849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGubT6at5bDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  # Bert Model instant \n",
        "  model = modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # Getting output for last layer of BERT\n",
        "  output_layer = model.get_pooled_output()\n",
        "  \n",
        "  # Number of outputs for last layer\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  # We will use one layer on top of BERT pretrained for creating classification model\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    \n",
        "    # Calcaulte prediction probabilites and loss\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8uV9lV7rNKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  \n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    # reading features input\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "    \n",
        "    # checking if training mode\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    \n",
        "    # create simple classification model\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings)\n",
        "    \n",
        "    # getting variables for intialization and using pretrained init checkpoint\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # defining optimizar function\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      \n",
        "      # Training estimator spec\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "      # accuracy, loss, auc, F1, precision and recall metrics for evaluation\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predictions)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predictions) \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn,\n",
        "                      [per_example_loss, label_ids, logits, is_real_example])\n",
        "      # estimator spec for evalaution\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics,\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    else:\n",
        "      # estimator spec for predictions\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities},\n",
        "          scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTqtSwkdrV4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ace66566-c1ad-46da-f481-ec8c421e01c8"
      },
      "source": [
        "# Define TPU configs\n",
        "# USE_TPU = True\n",
        "# TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "if USE_TPU:\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "else:\n",
        "  tpu_cluster_resolver = None\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Irf5yKrY8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=USE_TPU,\n",
        "    use_one_hot_embeddings=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd6SEwy7rtmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f15cfaf7-601e-44b9-ca56-013ba77d85f6"
      },
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9ed7a0a158>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://nlp_bert_quora/outputs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.92.11.106:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9ed70a6e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.92.11.106:8470', '_evaluation_master': 'grpc://10.92.11.106:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f9f14fe8198>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GnOLanSrvmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6898220-a047-4a88-dcb7-4f9bdbd55944"
      },
      "source": [
        "# Train the model.\n",
        "print('QQP on BERT base model normally takes about 1 hour on TPU and 15-20 hours on GPU. Please wait...')\n",
        "print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_train_examples))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "# we are using `file_based_input_fn_builder` for creating input function from TF_RECORD file\n",
        "train_input_fn = run_classifier.file_based_input_fn_builder(TRAIN_TF_RECORD,\n",
        "                                                            seq_length=MAX_SEQ_LENGTH,\n",
        "                                                            is_training=True,\n",
        "                                                            drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('***** Finished training at {} *****'.format(datetime.datetime.now()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QQP on BERT base model normally takes about 1 hour on TPU and 15-20 hours on GPU. Please wait...\n",
            "***** Started training at 2020-03-28 04:13:27.876836 *****\n",
            "  Num examples = 363849\n",
            "  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 22740\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9f310c76a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9f310c76a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.9449615, step = 1000\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.0138338, step = 2000 (86.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.5983\n",
            "INFO:tensorflow:examples/sec: 371.147\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.015894057, step = 3000 (73.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.6076\n",
            "INFO:tensorflow:examples/sec: 435.443\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.020605184, step = 4000 (75.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.164\n",
            "INFO:tensorflow:examples/sec: 421.247\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:loss = 0.14589742, step = 5000 (76.462 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0784\n",
            "INFO:tensorflow:examples/sec: 418.507\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.007529572, step = 6000 (77.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9445\n",
            "INFO:tensorflow:examples/sec: 414.225\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 7000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.01324083, step = 7000 (73.831 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.5446\n",
            "INFO:tensorflow:examples/sec: 433.428\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.6645545, step = 8000 (75.513 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2427\n",
            "INFO:tensorflow:examples/sec: 423.767\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 9000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.9938823, step = 9000 (75.883 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.178\n",
            "INFO:tensorflow:examples/sec: 421.696\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.009060976, step = 10000 (74.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.4051\n",
            "INFO:tensorflow:examples/sec: 428.962\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 11000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.003929402, step = 11000 (72.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.7565\n",
            "INFO:tensorflow:examples/sec: 440.208\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 12000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.006018156, step = 12000 (76.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0106\n",
            "INFO:tensorflow:examples/sec: 416.341\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 13000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.1193378, step = 13000 (80.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.3837\n",
            "INFO:tensorflow:examples/sec: 396.278\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 914)\n",
            "INFO:tensorflow:Saving checkpoints for 14000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.84139794, step = 14000 (83.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 11.9177\n",
            "INFO:tensorflow:examples/sec: 381.366\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 648)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.03294937, step = 15000 (73.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.5213\n",
            "INFO:tensorflow:examples/sec: 432.681\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 398)\n",
            "INFO:tensorflow:Saving checkpoints for 16000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.119470894, step = 16000 (79.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.5404\n",
            "INFO:tensorflow:examples/sec: 401.292\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 43)\n",
            "INFO:tensorflow:Saving checkpoints for 17000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.7386854, step = 17000 (80.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.4853\n",
            "INFO:tensorflow:examples/sec: 399.53\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 18000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.16211711, step = 18000 (76.886 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0063\n",
            "INFO:tensorflow:examples/sec: 416.2\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 19000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.00028379448, step = 19000 (75.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.272\n",
            "INFO:tensorflow:examples/sec: 424.703\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.4982157, step = 20000 (73.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.603\n",
            "INFO:tensorflow:examples/sec: 435.297\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 21000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.2659049, step = 21000 (78.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7704\n",
            "INFO:tensorflow:examples/sec: 408.653\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 0)\n",
            "INFO:tensorflow:Saving checkpoints for 22000 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.197725, step = 22000 (77.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9374\n",
            "INFO:tensorflow:examples/sec: 413.996\n",
            "INFO:tensorflow:Enqueue next (740) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (740) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 0)\n",
            "INFO:tensorflow:loss = 2.6743364, step = 22740 (43.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 17.1477\n",
            "INFO:tensorflow:examples/sec: 548.728\n",
            "INFO:tensorflow:Saving checkpoints for 22740 into gs://nlp_bert_quora/outputs/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 2.6743364.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "***** Finished training at 2020-03-28 04:44:10.994906 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TQLhlp4tbKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "d7263d12-8593-4600-d3a9-a402a38fd976"
      },
      "source": [
        "# eval the model on train set.\n",
        "print('***** Started Train Set evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_train_examples))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "# eval input function for train set\n",
        "train_eval_input_fn = run_classifier.file_based_input_fn_builder(TRAIN_TF_RECORD,\n",
        "                                                           seq_length=MAX_SEQ_LENGTH,\n",
        "                                                           is_training=False,\n",
        "                                                           drop_remainder=True)\n",
        "# evalute on train set\n",
        "result = estimator.evaluate(input_fn=train_eval_input_fn, \n",
        "                            steps=int(num_train_examples/EVAL_BATCH_SIZE))\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "  print('  {} = {}'.format(key, str(result[key])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started Train Set evaluation at 2020-03-28 04:44:11.052678 *****\n",
            "  Num examples = 363849\n",
            "  Batch size = 8\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9eb44f36a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9eb44f36a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3322: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T04:44:16Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://nlp_bert_quora/outputs/model.ckpt-22740\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (45481) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (45481) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 12919)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 24743)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 36769)\n",
            "INFO:tensorflow:Evaluation [45481/45481]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-04:48:34\n",
            "INFO:tensorflow:Saving dict for global step 22740: auc = 0.94649243, eval_accuracy = 0.94676626, eval_loss = 0.2347885, f1_score = 0.92917085, global_step = 22740, loss = 0.23723073, precision = 0.913448, recall = 0.9454445\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22740: gs://nlp_bert_quora/outputs/model.ckpt-22740\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "***** Finished evaluation at 2020-03-28 04:48:36.613176 *****\n",
            "***** Eval results *****\n",
            "  auc = 0.94649243\n",
            "  eval_accuracy = 0.94676626\n",
            "  eval_loss = 0.2347885\n",
            "  f1_score = 0.92917085\n",
            "  global_step = 22740\n",
            "  loss = 0.23723073\n",
            "  precision = 0.913448\n",
            "  recall = 0.9454445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T1e660gr03D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "8f93b213-91c9-4fe8-9231-bca3080beccc"
      },
      "source": [
        "# Converting eval examples to features\n",
        "print(\"################  Processing Dev Data #####################\")\n",
        "EVAL_TF_RECORD = os.path.join(OUTPUT_DIR, \"eval.tf_record\")\n",
        "eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "num_eval_examples = len(eval_examples)\n",
        "run_classifier.file_based_convert_examples_to_features(eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer, EVAL_TF_RECORD)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################  Processing Dev Data #####################\n",
            "INFO:tensorflow:Writing example 0 of 40430\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-1\n",
            "INFO:tensorflow:tokens: [CLS] why are african - americans so beautiful ? [SEP] why are hispanic ##s so beautiful ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2339 2024 3060 1011 4841 2061 3376 1029 102 2339 2024 6696 2015 2061 3376 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-2\n",
            "INFO:tensorflow:tokens: [CLS] i want to pursue phd in computer science about social network , what is the open problem in social networks ? [SEP] i handle social media for a non - profit . should i start going to social media networking events ? are there any good ones in the bay area ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1045 2215 2000 7323 8065 1999 3274 2671 2055 2591 2897 1010 2054 2003 1996 2330 3291 1999 2591 6125 1029 102 1045 5047 2591 2865 2005 1037 2512 1011 5618 1012 2323 1045 2707 2183 2000 2591 2865 14048 2824 1029 2024 2045 2151 2204 3924 1999 1996 3016 2181 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-3\n",
            "INFO:tensorflow:tokens: [CLS] is there a reason why we should travel alone ? [SEP] what are some reasons to travel alone ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2003 2045 1037 3114 2339 2057 2323 3604 2894 1029 102 2054 2024 2070 4436 2000 3604 2894 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-4\n",
            "INFO:tensorflow:tokens: [CLS] why are people so obsessed with having a girlfriend / boyfriend ? [SEP] how can a single male have a child ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2339 2024 2111 2061 15896 2007 2383 1037 6513 1013 6898 1029 102 2129 2064 1037 2309 3287 2031 1037 2775 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: dev-5\n",
            "INFO:tensorflow:tokens: [CLS] what are some good baby girl names starting with d ? [SEP] what are some good baby girl names starting with d or h ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 2070 2204 3336 2611 3415 3225 2007 1040 1029 102 2054 2024 2070 2204 3336 2611 3415 3225 2007 1040 2030 1044 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 40430\n",
            "INFO:tensorflow:Writing example 20000 of 40430\n",
            "INFO:tensorflow:Writing example 30000 of 40430\n",
            "INFO:tensorflow:Writing example 40000 of 40430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4KLxG-utkmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "83b0ad3d-38ba-42e3-943f-dc9664d4b6de"
      },
      "source": [
        "# Eval the model on Dev set.\n",
        "print('***** Started Dev Set evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_eval_examples))\n",
        "print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "# eval input function for dev set\n",
        "eval_input_fn = run_classifier.file_based_input_fn_builder(EVAL_TF_RECORD,\n",
        "                                                           seq_length=MAX_SEQ_LENGTH,\n",
        "                                                           is_training=False,\n",
        "                                                           drop_remainder=True)\n",
        "# evalute on dev set\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=int(num_eval_examples/EVAL_BATCH_SIZE))\n",
        "print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "  print('  {} = {}'.format(key, str(result[key])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started Dev Set evaluation at 2020-03-28 04:49:02.850680 *****\n",
            "  Num examples = 40430\n",
            "  Batch size = 8\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9eb0f8e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9eb0f8e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T04:49:08Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://nlp_bert_quora/outputs/model.ckpt-22740\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (5053) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (5053) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Evaluation [5053/5053]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-04:49:47\n",
            "INFO:tensorflow:Saving dict for global step 22740: auc = 0.8985793, eval_accuracy = 0.9025332, eval_loss = 0.45464584, f1_score = 0.8696831, global_step = 22740, loss = 0.47837967, precision = 0.8562032, recall = 0.88359433\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22740: gs://nlp_bert_quora/outputs/model.ckpt-22740\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n",
            "***** Finished evaluation at 2020-03-28 04:49:47.768233 *****\n",
            "***** Eval results *****\n",
            "  auc = 0.8985793\n",
            "  eval_accuracy = 0.9025332\n",
            "  eval_loss = 0.45464584\n",
            "  f1_score = 0.8696831\n",
            "  global_step = 22740\n",
            "  loss = 0.47837967\n",
            "  precision = 0.8562032\n",
            "  recall = 0.88359433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLxqAOtpt9vH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6c07630-e7fb-4ac3-c0ce-44b30549fe9f"
      },
      "source": [
        "# Converting test examples to features\n",
        "print(\"################  Processing Test Data #####################\")\n",
        "TEST_TF_RECORD = os.path.join(OUTPUT_DIR, \"test.tf_record\")\n",
        "test_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "num_test_examples = len(test_examples)\n",
        "run_classifier.file_based_convert_examples_to_features(test_examples, label_list, MAX_SEQ_LENGTH, tokenizer, TEST_TF_RECORD)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################  Processing Test Data #####################\n",
            "test-0 ['id', 'question1', 'question2']\n",
            "INFO:tensorflow:Writing example 0 of 390965\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-1\n",
            "INFO:tensorflow:tokens: [CLS] would the idea of trump and putin in bed together scare you , given the geo ##pol ##itical implications ? [SEP] do you think that if donald trump were elected president , he would be able to restore relations with putin and russia as he said he could , based on the rocky relationship putin had with obama and bush ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2052 1996 2801 1997 8398 1998 22072 1999 2793 2362 12665 2017 1010 2445 1996 20248 18155 26116 13494 1029 102 2079 2017 2228 2008 2065 6221 8398 2020 2700 2343 1010 2002 2052 2022 2583 2000 9239 4262 2007 22072 1998 3607 2004 2002 2056 2002 2071 1010 2241 2006 1996 6857 3276 22072 2018 2007 8112 1998 5747 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-2\n",
            "INFO:tensorflow:tokens: [CLS] what are the top ten consumer - to - consumer e - commerce online ? [SEP] what are the top ten consumer - to - business e - commerce online ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2054 2024 1996 2327 2702 7325 1011 2000 1011 7325 1041 1011 6236 3784 1029 102 2054 2024 1996 2327 2702 7325 1011 2000 1011 2449 1041 1011 6236 3784 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-3\n",
            "INFO:tensorflow:tokens: [CLS] why don ' t people simply ' google ' instead of asking questions on quo ##ra ? [SEP] why do people ask quo ##ra questions instead of just searching google ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2339 2123 1005 1056 2111 3432 1005 8224 1005 2612 1997 4851 3980 2006 22035 2527 1029 102 2339 2079 2111 3198 22035 2527 3980 2612 1997 2074 6575 8224 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-4\n",
            "INFO:tensorflow:tokens: [CLS] is it safe to invest in social trade bi ##z ? [SEP] is social trade gen ##iu ##ne ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2003 2009 3647 2000 15697 1999 2591 3119 12170 2480 1029 102 2003 2591 3119 8991 17922 2638 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: test-5\n",
            "INFO:tensorflow:tokens: [CLS] if the universe is expanding then does matter also expand ? [SEP] if universe and space is expanding ? does that mean anything that occupies space is also expanding ? [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2065 1996 5304 2003 9186 2059 2515 3043 2036 7818 1029 102 2065 5304 1998 2686 2003 9186 1029 2515 2008 2812 2505 2008 14133 2686 2003 2036 9186 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 390965\n",
            "INFO:tensorflow:Writing example 20000 of 390965\n",
            "INFO:tensorflow:Writing example 30000 of 390965\n",
            "INFO:tensorflow:Writing example 40000 of 390965\n",
            "INFO:tensorflow:Writing example 50000 of 390965\n",
            "INFO:tensorflow:Writing example 60000 of 390965\n",
            "INFO:tensorflow:Writing example 70000 of 390965\n",
            "INFO:tensorflow:Writing example 80000 of 390965\n",
            "INFO:tensorflow:Writing example 90000 of 390965\n",
            "INFO:tensorflow:Writing example 100000 of 390965\n",
            "INFO:tensorflow:Writing example 110000 of 390965\n",
            "INFO:tensorflow:Writing example 120000 of 390965\n",
            "INFO:tensorflow:Writing example 130000 of 390965\n",
            "INFO:tensorflow:Writing example 140000 of 390965\n",
            "INFO:tensorflow:Writing example 150000 of 390965\n",
            "INFO:tensorflow:Writing example 160000 of 390965\n",
            "INFO:tensorflow:Writing example 170000 of 390965\n",
            "INFO:tensorflow:Writing example 180000 of 390965\n",
            "INFO:tensorflow:Writing example 190000 of 390965\n",
            "INFO:tensorflow:Writing example 200000 of 390965\n",
            "INFO:tensorflow:Writing example 210000 of 390965\n",
            "INFO:tensorflow:Writing example 220000 of 390965\n",
            "INFO:tensorflow:Writing example 230000 of 390965\n",
            "INFO:tensorflow:Writing example 240000 of 390965\n",
            "INFO:tensorflow:Writing example 250000 of 390965\n",
            "INFO:tensorflow:Writing example 260000 of 390965\n",
            "INFO:tensorflow:Writing example 270000 of 390965\n",
            "INFO:tensorflow:Writing example 280000 of 390965\n",
            "INFO:tensorflow:Writing example 290000 of 390965\n",
            "INFO:tensorflow:Writing example 300000 of 390965\n",
            "INFO:tensorflow:Writing example 310000 of 390965\n",
            "INFO:tensorflow:Writing example 320000 of 390965\n",
            "INFO:tensorflow:Writing example 330000 of 390965\n",
            "INFO:tensorflow:Writing example 340000 of 390965\n",
            "INFO:tensorflow:Writing example 350000 of 390965\n",
            "INFO:tensorflow:Writing example 360000 of 390965\n",
            "INFO:tensorflow:Writing example 370000 of 390965\n",
            "INFO:tensorflow:Writing example 380000 of 390965\n",
            "INFO:tensorflow:Writing example 390000 of 390965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMKvcHhluBb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b681e6d3-a21d-493c-ebd7-8aaf0e5666f5"
      },
      "source": [
        "# Predictions on test set.\n",
        "print('***** Started Prediction at {} *****'.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(num_test_examples))\n",
        "print('  Batch size = {}'.format(PREDICT_BATCH_SIZE))\n",
        "# predict input function for test set\n",
        "test_input_fn = run_classifier.file_based_input_fn_builder(TEST_TF_RECORD,\n",
        "                                                           seq_length=MAX_SEQ_LENGTH,\n",
        "                                                           is_training=False,\n",
        "                                                           drop_remainder=True)\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "# predict on test set\n",
        "result = list(estimator.predict(input_fn=test_input_fn))\n",
        "print('***** Finished Prediction at {} *****'.format(datetime.datetime.now()))\n",
        "\n",
        "# saving test predictions\n",
        "output_test_file = os.path.join(OUTPUT_DIR, \"test_predictions.txt\")\n",
        "with tf.gfile.GFile(output_test_file, \"w\") as writer:\n",
        "  for (example_i, predictions_i) in enumerate(result):\n",
        "    writer.write(\"%s , %s\\n\" % (test_examples[example_i].guid, str(predictions_i['probabilities'][1])))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Started Prediction at 2020-03-28 04:53:58.615474 *****\n",
            "  Num examples = 390965\n",
            "  Batch size = 8\n",
            "WARNING: Entity <function file_based_input_fn_builder.<locals>.input_fn.<locals>.<lambda> at 0x7f9eb2138598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING: Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f9eb21386a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function _InputsWithStoppingSignals.insert_stopping_signal.<locals>._map_fn at 0x7f9eb2138d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function _InputsWithStoppingSignals.__init__.<locals>._set_mask at 0x7f9eb1dfd268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "***** Finished Prediction at 2020-03-28 04:58:12.167372 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWhTKr7DXs8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}